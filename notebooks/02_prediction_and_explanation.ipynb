{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Customer Churn Prediction - Prediction and Explanation Workflow\n",
                "\n",
                "This notebook demonstrates how to use the trained model to make predictions and generate SHAP explanations.\n",
                "\n",
                "## Overview\n",
                "\n",
                "We'll cover:\n",
                "1. Loading a trained model from the repository\n",
                "2. Making single customer predictions\n",
                "3. Batch predictions for multiple customers\n",
                "4. Computing SHAP explanations\n",
                "5. Interpreting feature contributions\n",
                "6. Visualizing SHAP values"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "\n",
                "# Import our services\n",
                "from services.prediction import ChurnPredictor, CustomerRecord\n",
                "from services.explainability import SHAPExplainer\n",
                "from services.model_repository import ModelRepository\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "# Initialize SHAP\n",
                "shap.initjs()\n",
                "\n",
                "print(\"✓ All imports successful\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Load Trained Model\n",
                "\n",
                "First, let's see what models are available and load one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize repository\n",
                "repo = ModelRepository()\n",
                "\n",
                "# List available versions\n",
                "versions = repo.list_versions()\n",
                "\n",
                "print(f\"Available model versions: {len(versions)}\\n\")\n",
                "for v in versions[-5:]:  # Show last 5\n",
                "    print(f\"Version: {v.version}\")\n",
                "    print(f\"  Recall: {v.metadata.get('recall', 'N/A'):.4f}\")\n",
                "    print(f\"  Precision: {v.metadata.get('precision', 'N/A'):.4f}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize predictor (loads latest model by default)\n",
                "predictor = ChurnPredictor()\n",
                "\n",
                "print(f\"✓ Loaded model version: {predictor.model_version}\")\n",
                "print(f\"  Number of features: {len(predictor.feature_names)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Single Customer Prediction\n",
                "\n",
                "Let's make a prediction for a single customer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a customer record\n",
                "customer = CustomerRecord(\n",
                "    customer_id=\"CUST_001\",\n",
                "    features={\n",
                "        'tenure_months': 12,\n",
                "        'monthly_charges': 75.50,\n",
                "        'total_charges': 906.00,\n",
                "        'contract_type': 'Month-to-month',\n",
                "        'payment_method': 'Electronic check',\n",
                "        'internet_service': 'Fiber optic',\n",
                "        'online_security': 'No',\n",
                "        'online_backup': 'No',\n",
                "        'device_protection': 'No',\n",
                "        'tech_support': 'No',\n",
                "        'streaming_tv': 'Yes',\n",
                "        'streaming_movies': 'Yes'\n",
                "    }\n",
                ")\n",
                "\n",
                "# Make prediction with explanations\n",
                "result = predictor.predict_single(customer, include_explanations=True)\n",
                "\n",
                "print(f\"Customer ID: {result.customer_id}\")\n",
                "print(f\"Churn Probability: {result.churn_probability:.3f}\")\n",
                "print(f\"High Risk: {'YES' if result.is_high_risk else 'NO'}\")\n",
                "print(f\"Model Version: {result.model_version}\")\n",
                "print(f\"\\nTop Contributing Features:\")\n",
                "for feature, value in result.top_features:\n",
                "    direction = \"increases\" if value > 0 else \"decreases\"\n",
                "    print(f\"  {feature}: {value:.4f} ({direction} churn risk)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Batch Predictions\n",
                "\n",
                "Now let's make predictions for multiple customers at once."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test data\n",
                "test_data = pd.read_csv('../data/raw/test_data.csv')\n",
                "\n",
                "print(f\"Test data shape: {test_data.shape}\")\n",
                "test_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make batch predictions\n",
                "results = predictor.predict_batch(test_data.head(50))  # Predict for first 50 customers\n",
                "\n",
                "# Convert to DataFrame\n",
                "results_df = pd.DataFrame([\n",
                "    {\n",
                "        'customer_id': r.customer_id,\n",
                "        'churn_probability': r.churn_probability,\n",
                "        'is_high_risk': r.is_high_risk,\n",
                "        'actual_churn': test_data.loc[test_data.index[i], 'churn'] if i < len(test_data) else None\n",
                "    }\n",
                "    for i, r in enumerate(results)\n",
                "])\n",
                "\n",
                "print(f\"\\nPrediction Summary:\")\n",
                "print(f\"  Total customers: {len(results_df)}\")\n",
                "print(f\"  High-risk accounts: {results_df['is_high_risk'].sum()} ({results_df['is_high_risk'].mean():.1%})\")\n",
                "print(f\"  Average churn probability: {results_df['churn_probability'].mean():.3f}\")\n",
                "print(f\"  Min probability: {results_df['churn_probability'].min():.3f}\")\n",
                "print(f\"  Max probability: {results_df['churn_probability'].max():.3f}\")\n",
                "\n",
                "results_df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize prediction distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Histogram of probabilities\n",
                "axes[0].hist(results_df['churn_probability'], bins=20, edgecolor='black', alpha=0.7)\n",
                "axes[0].axvline(x=0.5, color='red', linestyle='--', label='High-Risk Threshold')\n",
                "axes[0].set_xlabel('Churn Probability')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Distribution of Churn Probabilities')\n",
                "axes[0].legend()\n",
                "\n",
                "# High-risk vs low-risk\n",
                "risk_counts = results_df['is_high_risk'].value_counts()\n",
                "axes[1].bar(['Low Risk', 'High Risk'], [risk_counts.get(False, 0), risk_counts.get(True, 0)], \n",
                "            color=['green', 'red'], alpha=0.7)\n",
                "axes[1].set_ylabel('Count')\n",
                "axes[1].set_title('Risk Classification')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: SHAP Explanations\n",
                "\n",
                "Let's compute detailed SHAP explanations to understand feature contributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize SHAP explainer\n",
                "explainer = SHAPExplainer(predictor.model, predictor.transformer)\n",
                "\n",
                "print(\"✓ SHAP explainer initialized\")\n",
                "print(f\"  Background samples: {explainer.background_size}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select a few customers for detailed explanation\n",
                "sample_customers = test_data.head(10)\n",
                "\n",
                "# Compute SHAP values\n",
                "shap_values = explainer.explain(sample_customers)\n",
                "\n",
                "print(f\"SHAP values shape: {shap_values.shape}\")\n",
                "print(f\"Number of features: {len(predictor.feature_names)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Visualize SHAP Explanations\n",
                "\n",
                "Let's create various visualizations to understand feature importance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Waterfall plot for a single customer\n",
                "customer_idx = 0\n",
                "\n",
                "print(f\"Explaining customer at index {customer_idx}\")\n",
                "print(f\"Predicted probability: {predictor.model.predict_proba(predictor.transformer.transform(sample_customers.iloc[customer_idx:customer_idx+1]))[0, 1]:.3f}\")\n",
                "\n",
                "# Create SHAP explanation object\n",
                "shap_explanation = shap.Explanation(\n",
                "    values=shap_values[customer_idx],\n",
                "    base_values=explainer.explainer.expected_value,\n",
                "    data=predictor.transformer.transform(sample_customers.iloc[customer_idx:customer_idx+1])[0],\n",
                "    feature_names=predictor.feature_names\n",
                ")\n",
                "\n",
                "# Waterfall plot\n",
                "shap.plots.waterfall(shap_explanation, max_display=10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Force plot for a single customer\n",
                "shap.plots.force(\n",
                "    explainer.explainer.expected_value,\n",
                "    shap_values[customer_idx],\n",
                "    predictor.transformer.transform(sample_customers.iloc[customer_idx:customer_idx+1])[0],\n",
                "    feature_names=predictor.feature_names\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary plot showing feature importance across all samples\n",
                "shap.summary_plot(\n",
                "    shap_values,\n",
                "    predictor.transformer.transform(sample_customers),\n",
                "    feature_names=predictor.feature_names,\n",
                "    max_display=15\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bar plot of mean absolute SHAP values\n",
                "shap.summary_plot(\n",
                "    shap_values,\n",
                "    predictor.transformer.transform(sample_customers),\n",
                "    feature_names=predictor.feature_names,\n",
                "    plot_type=\"bar\",\n",
                "    max_display=15\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Analyze Top Features\n",
                "\n",
                "Let's identify the most important features across all customers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate mean absolute SHAP values\n",
                "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
                "\n",
                "# Create DataFrame\n",
                "feature_importance_df = pd.DataFrame({\n",
                "    'feature': predictor.feature_names,\n",
                "    'mean_abs_shap': mean_abs_shap\n",
                "}).sort_values('mean_abs_shap', ascending=False)\n",
                "\n",
                "print(\"Top 10 Most Important Features:\")\n",
                "print(feature_importance_df.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize top features\n",
                "plt.figure(figsize=(10, 6))\n",
                "top_features = feature_importance_df.head(10)\n",
                "plt.barh(top_features['feature'], top_features['mean_abs_shap'])\n",
                "plt.xlabel('Mean Absolute SHAP Value')\n",
                "plt.title('Top 10 Feature Importances (SHAP)')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Verify SHAP Additivity\n",
                "\n",
                "SHAP values should satisfy the additivity property: sum of SHAP values = prediction - base value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify additivity for each customer\n",
                "predictions = predictor.model.predict_proba(\n",
                "    predictor.transformer.transform(sample_customers)\n",
                ")[:, 1]\n",
                "\n",
                "base_value = explainer.explainer.expected_value\n",
                "\n",
                "print(f\"Base value (expected value): {base_value:.4f}\\n\")\n",
                "\n",
                "for i in range(min(5, len(sample_customers))):\n",
                "    shap_sum = shap_values[i].sum()\n",
                "    prediction = predictions[i]\n",
                "    expected_sum = prediction - base_value\n",
                "    is_valid = explainer.validate_shap_sum(shap_values[i], prediction, base_value)\n",
                "    \n",
                "    print(f\"Customer {i}:\")\n",
                "    print(f\"  Prediction: {prediction:.4f}\")\n",
                "    print(f\"  SHAP sum: {shap_sum:.4f}\")\n",
                "    print(f\"  Expected (pred - base): {expected_sum:.4f}\")\n",
                "    print(f\"  Difference: {abs(shap_sum - expected_sum):.6f}\")\n",
                "    print(f\"  Valid: {'✓' if is_valid else '✗'}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Compare High-Risk vs Low-Risk Customers\n",
                "\n",
                "Let's analyze the differences between high-risk and low-risk customers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classify customers\n",
                "high_risk_mask = predictions >= 0.5\n",
                "low_risk_mask = predictions < 0.5\n",
                "\n",
                "print(f\"High-risk customers: {high_risk_mask.sum()}\")\n",
                "print(f\"Low-risk customers: {low_risk_mask.sum()}\")\n",
                "\n",
                "# Compare average SHAP values\n",
                "if high_risk_mask.sum() > 0 and low_risk_mask.sum() > 0:\n",
                "    high_risk_shap = shap_values[high_risk_mask].mean(axis=0)\n",
                "    low_risk_shap = shap_values[low_risk_mask].mean(axis=0)\n",
                "    \n",
                "    comparison_df = pd.DataFrame({\n",
                "        'feature': predictor.feature_names,\n",
                "        'high_risk_shap': high_risk_shap,\n",
                "        'low_risk_shap': low_risk_shap,\n",
                "        'difference': high_risk_shap - low_risk_shap\n",
                "    }).sort_values('difference', ascending=False)\n",
                "    \n",
                "    print(\"\\nTop features differentiating high-risk from low-risk:\")\n",
                "    print(comparison_df.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this notebook, we:\n",
                "\n",
                "1. ✓ Loaded a trained model from the repository\n",
                "2. ✓ Made single customer predictions\n",
                "3. ✓ Performed batch predictions\n",
                "4. ✓ Computed SHAP explanations\n",
                "5. ✓ Visualized feature contributions\n",
                "6. ✓ Verified SHAP additivity property\n",
                "7. ✓ Analyzed differences between risk groups\n",
                "\n",
                "## Key Insights\n",
                "\n",
                "- SHAP values provide transparent explanations for each prediction\n",
                "- Feature importance varies by customer\n",
                "- The additivity property ensures mathematical consistency\n",
                "- Visualizations help communicate model behavior to stakeholders"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "- **Deploy Predictions**: Integrate predictions into business workflows\n",
                "- **Monitor Performance**: Track model accuracy over time (see next notebook)\n",
                "- **Refine Threshold**: Adjust high-risk threshold based on business costs\n",
                "- **Feature Engineering**: Use SHAP insights to create better features\n",
                "- **A/B Testing**: Compare different model versions in production"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}